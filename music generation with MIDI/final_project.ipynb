{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1d92190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f0371c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: Beethoven/beethoven_opus22_1_format0.mid\n",
      "Loading Music File: Beethoven/appass_2_format0.mid\n",
      "Loading Music File: Beethoven/waldstein_1_format0.mid\n",
      "Loading Music File: Beethoven/beethoven_opus22_4_format0.mid\n",
      "Loading Music File: Beethoven/pathetique_3_format0.mid\n",
      "Loading Music File: Beethoven/mond_3_format0.mid\n",
      "Loading Music File: Beethoven/beethoven_opus10_3_format0.mid\n",
      "Loading Music File: Beethoven/waldstein_2_format0.mid\n",
      "Loading Music File: Beethoven/appass_1_format0.mid\n",
      "Loading Music File: Beethoven/beethoven_opus22_2_format0.mid\n",
      "Loading Music File: Beethoven/mond_1_format0.mid\n",
      "Loading Music File: Beethoven/pathetique_1_format0.mid\n",
      "Loading Music File: Beethoven/beethoven_opus10_1_format0.mid\n",
      "Loading Music File: Beethoven/appass_3_format0.mid\n",
      "Loading Music File: Beethoven/beethoven_opus22_3_format0.mid\n",
      "Loading Music File: Beethoven/beethoven_les_adieux_1_format0.mid\n",
      "Loading Music File: Beethoven/waldstein_3_format0.mid\n",
      "Loading Music File: Beethoven/beethoven_opus10_2_format0.mid\n",
      "Loading Music File: Beethoven/pathetique_2_format0.mid\n",
      "Loading Music File: Beethoven/mond_2_format0.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuzhijun/Desktop/csci1470/Music-Generation-Using-Deep-Learning/wavenet.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  notes_array = np.array([self.read_midi(path + i) for i in files])\n"
     ]
    }
   ],
   "source": [
    "from wavenet import Preprocess\n",
    "\n",
    "pre = Preprocess()\n",
    "notes_array = pre.read_all_midi(path='Beethoven/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6c9fd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuzhijun/Desktop/csci1470/Music-Generation-Using-Deep-Learning/wavenet.py:62: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  new_music = np.array(new_music)\n"
     ]
    }
   ],
   "source": [
    "# define training and testing data\n",
    "x_tr, x_val, y_tr, y_val = pre.prepare(notes_array)\n",
    "unique_x, unique_y = pre.get_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3156849a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 21:50:43.016294: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 32, 100)           16200     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 32, 64)            19264     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 16, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 8, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 8, 256)            98560     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 4, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 256)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 162)               41634     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,154\n",
      "Trainable params: 266,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "253/253 [==============================] - 20s 74ms/step - loss: 4.6048 - acc: 0.0468 - val_loss: 4.3382 - val_acc: 0.0869\n",
      "Epoch 2/100\n",
      "253/253 [==============================] - 13s 50ms/step - loss: 3.9798 - acc: 0.1195 - val_loss: 3.9496 - val_acc: 0.1442\n",
      "Epoch 3/100\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 3.7150 - acc: 0.1492 - val_loss: 3.8084 - val_acc: 0.1541\n",
      "Epoch 4/100\n",
      "253/253 [==============================] - 13s 53ms/step - loss: 3.5554 - acc: 0.1656 - val_loss: 3.6936 - val_acc: 0.1703\n",
      "Epoch 5/100\n",
      "253/253 [==============================] - 14s 57ms/step - loss: 3.4357 - acc: 0.1776 - val_loss: 3.6015 - val_acc: 0.1742\n",
      "Epoch 6/100\n",
      "253/253 [==============================] - 20s 78ms/step - loss: 3.3424 - acc: 0.1857 - val_loss: 3.5417 - val_acc: 0.1772\n",
      "Epoch 7/100\n",
      "253/253 [==============================] - 14s 54ms/step - loss: 3.2616 - acc: 0.1956 - val_loss: 3.4981 - val_acc: 0.1842\n",
      "Epoch 8/100\n",
      "253/253 [==============================] - 16s 64ms/step - loss: 3.1894 - acc: 0.2012 - val_loss: 3.4551 - val_acc: 0.1863\n",
      "Epoch 9/100\n",
      "253/253 [==============================] - 16s 63ms/step - loss: 3.1222 - acc: 0.2126 - val_loss: 3.3783 - val_acc: 0.1974\n",
      "Epoch 10/100\n",
      "253/253 [==============================] - 16s 65ms/step - loss: 3.0671 - acc: 0.2171 - val_loss: 3.3560 - val_acc: 0.1938\n",
      "Epoch 11/100\n",
      "253/253 [==============================] - 17s 69ms/step - loss: 3.0125 - acc: 0.2232 - val_loss: 3.3110 - val_acc: 0.1999\n",
      "Epoch 12/100\n",
      "253/253 [==============================] - 17s 68ms/step - loss: 2.9587 - acc: 0.2298 - val_loss: 3.2769 - val_acc: 0.2037\n",
      "Epoch 13/100\n",
      "253/253 [==============================] - 17s 68ms/step - loss: 2.9125 - acc: 0.2394 - val_loss: 3.2429 - val_acc: 0.2070\n",
      "Epoch 14/100\n",
      "253/253 [==============================] - 14s 57ms/step - loss: 2.8665 - acc: 0.2441 - val_loss: 3.2282 - val_acc: 0.2051\n",
      "Epoch 15/100\n",
      "253/253 [==============================] - 17s 67ms/step - loss: 2.8248 - acc: 0.2492 - val_loss: 3.2058 - val_acc: 0.2125\n",
      "Epoch 16/100\n",
      "253/253 [==============================] - 17s 67ms/step - loss: 2.7839 - acc: 0.2516 - val_loss: 3.1719 - val_acc: 0.2135\n",
      "Epoch 17/100\n",
      "253/253 [==============================] - 17s 68ms/step - loss: 2.7461 - acc: 0.2601 - val_loss: 3.1254 - val_acc: 0.2227\n",
      "Epoch 18/100\n",
      "253/253 [==============================] - 20s 79ms/step - loss: 2.7077 - acc: 0.2653 - val_loss: 3.1246 - val_acc: 0.2240\n",
      "Epoch 19/100\n",
      "253/253 [==============================] - 17s 65ms/step - loss: 2.6818 - acc: 0.2685 - val_loss: 3.1054 - val_acc: 0.2202\n",
      "Epoch 20/100\n",
      "253/253 [==============================] - 17s 68ms/step - loss: 2.6505 - acc: 0.2743 - val_loss: 3.0833 - val_acc: 0.2325\n",
      "Epoch 21/100\n",
      "253/253 [==============================] - 20s 80ms/step - loss: 2.6185 - acc: 0.2793 - val_loss: 3.0528 - val_acc: 0.2282\n",
      "Epoch 22/100\n",
      "253/253 [==============================] - 21s 81ms/step - loss: 2.5858 - acc: 0.2848 - val_loss: 3.0527 - val_acc: 0.2323\n",
      "Epoch 23/100\n",
      "253/253 [==============================] - 33s 131ms/step - loss: 2.5623 - acc: 0.2905 - val_loss: 3.0257 - val_acc: 0.2385\n",
      "Epoch 24/100\n",
      "253/253 [==============================] - 18s 71ms/step - loss: 2.5318 - acc: 0.2931 - val_loss: 3.0334 - val_acc: 0.2358\n",
      "Epoch 25/100\n",
      "253/253 [==============================] - 19s 75ms/step - loss: 2.5110 - acc: 0.2983 - val_loss: 3.0006 - val_acc: 0.2401\n",
      "Epoch 26/100\n",
      "253/253 [==============================] - 18s 70ms/step - loss: 2.4847 - acc: 0.3050 - val_loss: 2.9942 - val_acc: 0.2431\n",
      "Epoch 27/100\n",
      "253/253 [==============================] - 18s 70ms/step - loss: 2.4646 - acc: 0.3074 - val_loss: 2.9874 - val_acc: 0.2443\n",
      "Epoch 28/100\n",
      "253/253 [==============================] - 17s 69ms/step - loss: 2.4364 - acc: 0.3116 - val_loss: 2.9812 - val_acc: 0.2442\n",
      "Epoch 29/100\n",
      "253/253 [==============================] - 22s 85ms/step - loss: 2.4271 - acc: 0.3128 - val_loss: 2.9619 - val_acc: 0.2503\n",
      "Epoch 30/100\n",
      "253/253 [==============================] - 20s 78ms/step - loss: 2.4046 - acc: 0.3188 - val_loss: 2.9470 - val_acc: 0.2477\n",
      "Epoch 31/100\n",
      "253/253 [==============================] - 17s 69ms/step - loss: 2.3881 - acc: 0.3208 - val_loss: 2.9349 - val_acc: 0.2561\n",
      "Epoch 32/100\n",
      "253/253 [==============================] - 17s 68ms/step - loss: 2.3672 - acc: 0.3240 - val_loss: 2.9322 - val_acc: 0.2565\n",
      "Epoch 33/100\n",
      "253/253 [==============================] - 18s 69ms/step - loss: 2.3428 - acc: 0.3299 - val_loss: 2.9199 - val_acc: 0.2604\n",
      "Epoch 34/100\n",
      "253/253 [==============================] - 18s 71ms/step - loss: 2.3280 - acc: 0.3319 - val_loss: 2.9062 - val_acc: 0.2577\n",
      "Epoch 35/100\n",
      "253/253 [==============================] - 18s 73ms/step - loss: 2.3149 - acc: 0.3341 - val_loss: 2.9013 - val_acc: 0.2568\n",
      "Epoch 36/100\n",
      "253/253 [==============================] - 18s 70ms/step - loss: 2.3003 - acc: 0.3350 - val_loss: 2.8878 - val_acc: 0.2608\n",
      "Epoch 37/100\n",
      "253/253 [==============================] - 18s 70ms/step - loss: 2.2889 - acc: 0.3405 - val_loss: 2.8749 - val_acc: 0.2672\n",
      "Epoch 38/100\n",
      "253/253 [==============================] - 19s 73ms/step - loss: 2.2711 - acc: 0.3432 - val_loss: 2.8722 - val_acc: 0.2640\n",
      "Epoch 39/100\n",
      "253/253 [==============================] - 18s 71ms/step - loss: 2.2521 - acc: 0.3475 - val_loss: 2.8863 - val_acc: 0.2653\n",
      "Epoch 40/100\n",
      "253/253 [==============================] - 19s 74ms/step - loss: 2.2489 - acc: 0.3475 - val_loss: 2.8773 - val_acc: 0.2686\n",
      "Epoch 41/100\n",
      "253/253 [==============================] - 19s 76ms/step - loss: 2.2256 - acc: 0.3537 - val_loss: 2.8817 - val_acc: 0.2635\n",
      "Epoch 42/100\n",
      "253/253 [==============================] - 18s 73ms/step - loss: 2.2233 - acc: 0.3517 - val_loss: 2.8544 - val_acc: 0.2757\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253/253 [==============================] - 17s 69ms/step - loss: 2.2036 - acc: 0.3549 - val_loss: 2.8625 - val_acc: 0.2754\n",
      "Epoch 44/100\n",
      "253/253 [==============================] - 17s 67ms/step - loss: 2.1934 - acc: 0.3618 - val_loss: 2.8397 - val_acc: 0.2752\n",
      "Epoch 45/100\n",
      "253/253 [==============================] - 16s 65ms/step - loss: 2.1881 - acc: 0.3597 - val_loss: 2.8437 - val_acc: 0.2752\n",
      "Epoch 46/100\n",
      "253/253 [==============================] - 15s 60ms/step - loss: 2.1689 - acc: 0.3645 - val_loss: 2.8351 - val_acc: 0.2851\n",
      "Epoch 47/100\n",
      "253/253 [==============================] - 18s 70ms/step - loss: 2.1699 - acc: 0.3618 - val_loss: 2.8475 - val_acc: 0.2776\n",
      "Epoch 48/100\n",
      "253/253 [==============================] - 18s 70ms/step - loss: 2.1563 - acc: 0.3674 - val_loss: 2.8183 - val_acc: 0.2847\n",
      "Epoch 49/100\n",
      "253/253 [==============================] - 34s 136ms/step - loss: 2.1439 - acc: 0.3674 - val_loss: 2.8259 - val_acc: 0.2843\n",
      "Epoch 50/100\n",
      "253/253 [==============================] - 26s 101ms/step - loss: 2.1367 - acc: 0.3726 - val_loss: 2.8114 - val_acc: 0.2901\n",
      "Epoch 51/100\n",
      "253/253 [==============================] - 25s 99ms/step - loss: 2.1195 - acc: 0.3733 - val_loss: 2.8099 - val_acc: 0.2859\n",
      "Epoch 52/100\n",
      "253/253 [==============================] - 23s 89ms/step - loss: 2.1174 - acc: 0.3782 - val_loss: 2.8047 - val_acc: 0.2908\n",
      "Epoch 53/100\n",
      "253/253 [==============================] - 32s 128ms/step - loss: 2.1076 - acc: 0.3767 - val_loss: 2.8087 - val_acc: 0.2893\n",
      "Epoch 54/100\n",
      "253/253 [==============================] - 37s 142ms/step - loss: 2.0978 - acc: 0.3809 - val_loss: 2.7994 - val_acc: 0.2914\n",
      "Epoch 55/100\n",
      "253/253 [==============================] - 23s 92ms/step - loss: 2.0941 - acc: 0.3840 - val_loss: 2.7937 - val_acc: 0.2909\n",
      "Epoch 56/100\n",
      "253/253 [==============================] - 23s 91ms/step - loss: 2.0919 - acc: 0.3834 - val_loss: 2.8079 - val_acc: 0.2853\n",
      "Epoch 57/100\n",
      "253/253 [==============================] - 23s 91ms/step - loss: 2.0837 - acc: 0.3819 - val_loss: 2.7940 - val_acc: 0.3025\n",
      "Epoch 58/100\n",
      "253/253 [==============================] - 23s 91ms/step - loss: 2.0694 - acc: 0.3897 - val_loss: 2.7746 - val_acc: 0.2977\n",
      "Epoch 59/100\n",
      "253/253 [==============================] - 22s 89ms/step - loss: 2.0704 - acc: 0.3868 - val_loss: 2.7771 - val_acc: 0.2990\n",
      "Epoch 60/100\n",
      "253/253 [==============================] - 22s 89ms/step - loss: 2.0627 - acc: 0.3873 - val_loss: 2.7786 - val_acc: 0.3056\n",
      "Epoch 61/100\n",
      "253/253 [==============================] - 22s 87ms/step - loss: 2.0591 - acc: 0.3856 - val_loss: 2.7823 - val_acc: 0.3033\n",
      "Epoch 62/100\n",
      "253/253 [==============================] - 23s 92ms/step - loss: 2.0374 - acc: 0.3933 - val_loss: 2.7932 - val_acc: 0.3019\n",
      "Epoch 63/100\n",
      "253/253 [==============================] - 22s 88ms/step - loss: 2.0336 - acc: 0.3956 - val_loss: 2.7788 - val_acc: 0.3085\n",
      "Epoch 64/100\n",
      "253/253 [==============================] - 23s 91ms/step - loss: 2.0247 - acc: 0.3977 - val_loss: 2.7808 - val_acc: 0.3031\n",
      "Epoch 65/100\n",
      "253/253 [==============================] - 20s 77ms/step - loss: 2.0176 - acc: 0.4002 - val_loss: 2.7716 - val_acc: 0.3092\n",
      "Epoch 66/100\n",
      "253/253 [==============================] - 22s 87ms/step - loss: 2.0261 - acc: 0.3997 - val_loss: 2.7777 - val_acc: 0.3099\n",
      "Epoch 67/100\n",
      "253/253 [==============================] - 24s 95ms/step - loss: 2.0101 - acc: 0.4009 - val_loss: 2.7568 - val_acc: 0.3159\n",
      "Epoch 68/100\n",
      "253/253 [==============================] - 21s 82ms/step - loss: 1.9983 - acc: 0.4003 - val_loss: 2.7677 - val_acc: 0.3114\n",
      "Epoch 69/100\n",
      "253/253 [==============================] - 23s 89ms/step - loss: 1.9969 - acc: 0.4050 - val_loss: 2.7581 - val_acc: 0.3146\n",
      "Epoch 70/100\n",
      "253/253 [==============================] - 20s 78ms/step - loss: 1.9982 - acc: 0.3999 - val_loss: 2.7568 - val_acc: 0.3123\n",
      "Epoch 71/100\n",
      "253/253 [==============================] - 23s 93ms/step - loss: 1.9873 - acc: 0.4046 - val_loss: 2.7491 - val_acc: 0.3159\n",
      "Epoch 72/100\n",
      "253/253 [==============================] - 23s 89ms/step - loss: 1.9974 - acc: 0.4017 - val_loss: 2.7473 - val_acc: 0.3186\n",
      "Epoch 73/100\n",
      "253/253 [==============================] - 16s 64ms/step - loss: 1.9776 - acc: 0.4109 - val_loss: 2.7633 - val_acc: 0.3140\n",
      "Epoch 74/100\n",
      "253/253 [==============================] - 23s 89ms/step - loss: 1.9787 - acc: 0.4080 - val_loss: 2.7479 - val_acc: 0.3192\n",
      "Epoch 75/100\n",
      "253/253 [==============================] - 26s 101ms/step - loss: 1.9646 - acc: 0.4121 - val_loss: 2.7498 - val_acc: 0.3150\n",
      "Epoch 76/100\n",
      "253/253 [==============================] - 31s 122ms/step - loss: 1.9641 - acc: 0.4108 - val_loss: 2.7501 - val_acc: 0.3169\n",
      "Epoch 77/100\n",
      "253/253 [==============================] - 23s 91ms/step - loss: 1.9632 - acc: 0.4110 - val_loss: 2.7475 - val_acc: 0.3229\n",
      "Epoch 78/100\n",
      "253/253 [==============================] - 23s 89ms/step - loss: 1.9576 - acc: 0.4068 - val_loss: 2.7433 - val_acc: 0.3200\n",
      "Epoch 79/100\n",
      "253/253 [==============================] - 23s 89ms/step - loss: 1.9350 - acc: 0.4185 - val_loss: 2.7394 - val_acc: 0.3266\n",
      "Epoch 80/100\n",
      "253/253 [==============================] - 23s 91ms/step - loss: 1.9415 - acc: 0.4174 - val_loss: 2.7530 - val_acc: 0.3198\n",
      "Epoch 81/100\n",
      "253/253 [==============================] - 21s 81ms/step - loss: 1.9419 - acc: 0.4138 - val_loss: 2.7457 - val_acc: 0.3232\n",
      "Epoch 82/100\n",
      "253/253 [==============================] - 22s 87ms/step - loss: 1.9326 - acc: 0.4189 - val_loss: 2.7391 - val_acc: 0.3228\n",
      "Epoch 83/100\n",
      "253/253 [==============================] - 20s 78ms/step - loss: 1.9302 - acc: 0.4162 - val_loss: 2.7421 - val_acc: 0.3191\n",
      "Epoch 84/100\n",
      "253/253 [==============================] - 22s 86ms/step - loss: 1.9326 - acc: 0.4159 - val_loss: 2.7282 - val_acc: 0.3311\n",
      "Epoch 85/100\n",
      "253/253 [==============================] - 20s 81ms/step - loss: 1.9099 - acc: 0.4263 - val_loss: 2.7333 - val_acc: 0.3224\n",
      "Epoch 86/100\n",
      "253/253 [==============================] - 20s 78ms/step - loss: 1.9151 - acc: 0.4228 - val_loss: 2.7321 - val_acc: 0.3314\n",
      "Epoch 87/100\n",
      "253/253 [==============================] - 20s 79ms/step - loss: 1.9197 - acc: 0.4183 - val_loss: 2.7310 - val_acc: 0.3286\n",
      "Epoch 88/100\n",
      "253/253 [==============================] - 20s 80ms/step - loss: 1.9045 - acc: 0.4251 - val_loss: 2.7447 - val_acc: 0.3222\n",
      "Epoch 89/100\n",
      "253/253 [==============================] - 20s 79ms/step - loss: 1.9101 - acc: 0.4210 - val_loss: 2.7357 - val_acc: 0.3328\n",
      "Epoch 90/100\n",
      "253/253 [==============================] - 20s 80ms/step - loss: 1.9071 - acc: 0.4246 - val_loss: 2.7373 - val_acc: 0.3224\n",
      "Epoch 91/100\n",
      "253/253 [==============================] - 20s 81ms/step - loss: 1.8951 - acc: 0.4246 - val_loss: 2.7205 - val_acc: 0.3320\n",
      "Epoch 92/100\n",
      "253/253 [==============================] - 21s 82ms/step - loss: 1.8872 - acc: 0.4284 - val_loss: 2.7231 - val_acc: 0.3372\n",
      "Epoch 93/100\n",
      "253/253 [==============================] - 20s 80ms/step - loss: 1.8848 - acc: 0.4303 - val_loss: 2.7284 - val_acc: 0.3349\n",
      "Epoch 94/100\n",
      "253/253 [==============================] - 20s 79ms/step - loss: 1.8903 - acc: 0.4310 - val_loss: 2.7285 - val_acc: 0.3289\n",
      "Epoch 95/100\n",
      "253/253 [==============================] - 19s 76ms/step - loss: 1.8771 - acc: 0.4348 - val_loss: 2.7407 - val_acc: 0.3368\n",
      "Epoch 96/100\n",
      "253/253 [==============================] - 26s 103ms/step - loss: 1.8706 - acc: 0.4343 - val_loss: 2.7294 - val_acc: 0.3349\n",
      "Epoch 97/100\n",
      "253/253 [==============================] - 21s 83ms/step - loss: 1.8714 - acc: 0.4303 - val_loss: 2.7382 - val_acc: 0.3307\n",
      "Epoch 98/100\n",
      "253/253 [==============================] - 19s 77ms/step - loss: 1.8881 - acc: 0.4302 - val_loss: 2.7182 - val_acc: 0.3346\n",
      "Epoch 99/100\n",
      "253/253 [==============================] - 21s 81ms/step - loss: 1.8675 - acc: 0.4335 - val_loss: 2.7307 - val_acc: 0.3249\n",
      "Epoch 100/100\n",
      "253/253 [==============================] - 20s 81ms/step - loss: 1.8674 - acc: 0.4327 - val_loss: 2.7243 - val_acc: 0.3383\n"
     ]
    }
   ],
   "source": [
    "from wavenet import Wavenet\n",
    "\n",
    "model = Wavenet()\n",
    "model.construct(len(unique_x), len(unique_y))\n",
    "model.fit(x_tr, x_val, y_tr, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e09449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 642ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "predicted_output = model.predict(x_val, unique_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cb2126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "G#2\n",
      "0.5\n",
      "G#6\n",
      "B1\n",
      "B1\n",
      "6.9\n",
      "A5\n",
      "9.0.3.5\n",
      "1.3.7\n"
     ]
    }
   ],
   "source": [
    "from wavenet import ToMidi\n",
    "midi = ToMidi()\n",
    "midi.to_midi(predicted_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Oct 19 2022, 22:38:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "81bc6bb4078edff0d935dfe3ec9a2fa481bd7105e8c22492a837b35394154f2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
